{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import FraudDataset\n",
    "\n",
    "dataset = FraudDataset(\"yelp\")\n",
    "g = dataset[0]\n",
    "print(g.etypes)\n",
    "print(g.ntypes)\n",
    "print(g.ndata)\n",
    "print(g.ndata.keys())\n",
    "print()\n",
    "print(g.ndata[\"feature\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = g.ndata[\"train_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n",
    "\n",
    "mask = g.ndata[\"val_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n",
    "\n",
    "mask = g.ndata[\"test_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "import dgl.nn.pytorch as gnn\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "\n",
    "class GCN(pl.LightningModule):\n",
    "    # class GCN(nn.Module):\n",
    "    def __init__(self, g, in_feats, h_feats, num_classes, rel_names, batch_size=1):\n",
    "        super().__init__()\n",
    "        # len(output_nodes) = batch_size\n",
    "\n",
    "        self.labels = g.ndata[\"label\"]\n",
    "        self.train_mask = g.ndata[\"train_mask\"].to(bool)\n",
    "        self.val_mask = g.ndata[\"val_mask\"].to(bool)\n",
    "        self.test_mask = g.ndata[\"test_mask\"].to(bool)\n",
    "\n",
    "        if False:\n",
    "            self.f1 = F1Score(\"binary\").to(\"cuda\")\n",
    "        else:\n",
    "            self.f1 = F1Score(\"binary\")\n",
    "\n",
    "        self.conv0 = gnn.HeteroGraphConv(\n",
    "            {rel: gnn.SAGEConv(in_feats, h_feats, \"mean\") for rel in rel_names}\n",
    "        )\n",
    "        self.conv1 = gnn.HeteroGraphConv(\n",
    "            {rel: gnn.SAGEConv(h_feats, num_classes, \"mean\") for rel in rel_names}\n",
    "        )\n",
    "        # self.conv0 = gnn.HeteroGraphConv(\n",
    "        #     {\n",
    "        #         \"net_rsr\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #         \"net_rtr\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #         \"net_rur\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #     },\n",
    "        #     aggregate=\"sum\",\n",
    "        # )\n",
    "        # self.conv1 = gnn.HeteroGraphConv(\n",
    "        #     {\n",
    "        #         \"net_rsr\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #         \"net_rtr\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #         \"net_rur\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #     },\n",
    "        #     aggregate=\"sum\",\n",
    "        # )\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv0(g, in_feat)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        h = self.conv1(g, {\"review\": h})\n",
    "        return h\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # mini batch training -- https://docs.dgl.ai/en/latest/guide/minibatch-node.html#guide-minibatch-node-classification-sampler\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "\n",
    "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        self.log(\n",
    "            \"acc\", train_acc, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": train_acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        val_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "        f1 = self.f1(pred, self.labels[output_nodes]).item()\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_acc\",\n",
    "            val_acc,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            batch_size=len(output_nodes),\n",
    "        )\n",
    "        self.log(\"val_f1\", f1, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        return {\"val_loss\": loss, \"val_acc\": val_acc, \"val_f1\": f1}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        test_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "        f1 = self.f1(pred, self.labels[output_nodes]).item()\n",
    "\n",
    "        self.log(\n",
    "            \"test_loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        self.log(\n",
    "            \"test_acc\",\n",
    "            test_acc,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            batch_size=len(output_nodes),\n",
    "        )\n",
    "        self.log(\"f1\", f1, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        return {\"test_loss\": loss, \"test_acc\": test_acc, \"f1\": f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "from dgl.dataloading import DataLoader\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "batch_size = len(g.ndata[\"train_mask\"])\n",
    "train_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"train_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "val_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"val_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "test_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"test_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "g = g.to(device)\n",
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\n",
    "dataloader = DataLoader(g, train_idx, sampler, batch_size=batch_size)\n",
    "val_set = DataLoader(g, val_idx, sampler, batch_size=len(val_idx))\n",
    "test_set = DataLoader(g, test_idx, sampler, batch_size=len(test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "mlf_logger = MLFlowLogger()\n",
    "model = GCN(g, g.ndata[\"feature\"].shape[1], 16, dataset.num_classes, g.etypes)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5_000,\n",
    "    # accelerator=\"cpu\",\n",
    "    log_every_n_steps=1,\n",
    "    logger=mlf_logger\n",
    ")\n",
    "trainer.fit(model, dataloader,val_dataloaders=val_set)\n",
    "trainer.test(model, dataloaders=test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "features = {\"review\": g.ndata[\"feature\"].to(device)}\n",
    "model = model.to(device)\n",
    "logits = model(g.to(device), features)[\"review\"]\n",
    "test_mask = g.ndata[\"test_mask\"].cpu().to(bool)\n",
    "labels = g.ndata[\"label\"][test_mask].cpu()\n",
    "pred = logits.argmax(1)[test_mask].cpu()\n",
    "\n",
    "cm = confusion_matrix(labels, pred)\n",
    "cm = ConfusionMatrixDisplay(cm)\n",
    "cm.plot(cmap=\"Blues\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc93820af594536f6b5955ab92df2c64c8b670a927a628d84e8130e0bffc07a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
