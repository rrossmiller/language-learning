{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "['net_rsr', 'net_rtr', 'net_rur']\n",
      "['review']\n",
      "{'test_mask': tensor([0, 0, 0,  ..., 1, 0, 0], dtype=torch.uint8), 'val_mask': tensor([1, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8), 'train_mask': tensor([0, 1, 1,  ..., 0, 1, 1], dtype=torch.uint8), 'label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'feature': tensor([[0.0224, 0.0705, 0.4287,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        [0.0249, 1.0000, 1.0000,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        [0.0062, 0.0705, 0.4287,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        ...,\n",
      "        [0.0091, 0.3500, 0.4287,  ..., 0.4826, 0.8010, 0.1642],\n",
      "        [0.0062, 0.0705, 1.0000,  ..., 0.4428, 0.4478, 0.5871],\n",
      "        [0.0032, 0.3500, 0.4287,  ..., 0.4428, 0.4478, 0.5871]])}\n",
      "dict_keys(['test_mask', 'val_mask', 'train_mask', 'label', 'feature'])\n",
      "\n",
      "tensor([[0.0224, 0.0705, 0.4287,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        [0.0249, 1.0000, 1.0000,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        [0.0062, 0.0705, 0.4287,  ..., 0.5920, 0.1393, 0.4975],\n",
      "        ...,\n",
      "        [0.0091, 0.3500, 0.4287,  ..., 0.4826, 0.8010, 0.1642],\n",
      "        [0.0062, 0.0705, 1.0000,  ..., 0.4428, 0.4478, 0.5871],\n",
      "        [0.0032, 0.3500, 0.4287,  ..., 0.4428, 0.4478, 0.5871]])\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import FraudDataset\n",
    "\n",
    "dataset = FraudDataset(\"yelp\")\n",
    "g = dataset[0]\n",
    "print(g.etypes)\n",
    "print(g.ntypes)\n",
    "print(g.ndata)\n",
    "print(g.ndata.keys())\n",
    "print()\n",
    "print(g.ndata[\"feature\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 27441, 1: 4726} tensor(0.8531)\n",
      "{0: 3944, 1: 651} tensor(0.8583)\n",
      "{0: 7892, 1: 1300} tensor(0.8586)\n"
     ]
    }
   ],
   "source": [
    "mask = g.ndata[\"train_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n",
    "\n",
    "mask = g.ndata[\"val_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n",
    "\n",
    "mask = g.ndata[\"test_mask\"].to(bool)\n",
    "l = {0: 0, 1: 0}\n",
    "\n",
    "for x in g.ndata[\"label\"][mask].numpy():\n",
    "    l[x] += 1\n",
    "print(l, l[0] / (mask.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "import dgl.nn.pytorch as gnn\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "\n",
    "class GCN(pl.LightningModule):\n",
    "    # class GCN(nn.Module):\n",
    "    def __init__(self, g, in_feats, h_feats, num_classes, rel_names, batch_size=1):\n",
    "        super().__init__()\n",
    "        # len(output_nodes) = batch_size\n",
    "\n",
    "        self.labels = g.ndata[\"label\"]\n",
    "        self.train_mask = g.ndata[\"train_mask\"].to(bool)\n",
    "        self.val_mask = g.ndata[\"val_mask\"].to(bool)\n",
    "        self.test_mask = g.ndata[\"test_mask\"].to(bool)\n",
    "\n",
    "        if False:\n",
    "            self.f1 = F1Score(\"binary\").to(\"cuda\")\n",
    "        else:\n",
    "            self.f1 = F1Score(\"binary\")\n",
    "\n",
    "        self.conv0 = gnn.HeteroGraphConv(\n",
    "            {rel: gnn.SAGEConv(in_feats, h_feats, \"mean\") for rel in rel_names}\n",
    "        )\n",
    "        self.conv1 = gnn.HeteroGraphConv(\n",
    "            {rel: gnn.SAGEConv(h_feats, num_classes, \"mean\") for rel in rel_names}\n",
    "        )\n",
    "        # self.conv0 = gnn.HeteroGraphConv(\n",
    "        #     {\n",
    "        #         \"net_rsr\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #         \"net_rtr\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #         \"net_rur\": gnn.GraphConv(in_feats, h_feats),\n",
    "        #     },\n",
    "        #     aggregate=\"sum\",\n",
    "        # )\n",
    "        # self.conv1 = gnn.HeteroGraphConv(\n",
    "        #     {\n",
    "        #         \"net_rsr\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #         \"net_rtr\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #         \"net_rur\": gnn.GraphConv(h_feats, num_classes),\n",
    "        #     },\n",
    "        #     aggregate=\"sum\",\n",
    "        # )\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv0(g, in_feat)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        h = self.conv1(g, {\"review\": h})\n",
    "        return h\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # mini batch training -- https://docs.dgl.ai/en/latest/guide/minibatch-node.html#guide-minibatch-node-classification-sampler\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "\n",
    "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        self.log(\n",
    "            \"acc\", train_acc, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        return {\"loss\": loss, \"acc\": train_acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        val_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "        f1 = self.f1(pred, self.labels[output_nodes]).item()\n",
    "\n",
    "        self.log(\n",
    "            \"val_loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_acc\",\n",
    "            val_acc,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            batch_size=len(output_nodes),\n",
    "        )\n",
    "        self.log(\"val_f1\", f1, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        return {\"val_loss\": loss, \"val_acc\": val_acc, \"val_f1\": f1}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Forward\n",
    "        input_nodes, output_nodes, blocks = batch\n",
    "\n",
    "        # fwd pass\n",
    "        h = blocks[0].ndata[\"feature\"]\n",
    "        h = self.conv0(blocks[0], h)\n",
    "        h = F.relu(h[\"review\"])\n",
    "        logits = self.conv1(blocks[1], {\"review\": h})[\"review\"]\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1).to(torch.int8)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            self.labels[output_nodes],\n",
    "        )\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        test_acc = (pred == self.labels[output_nodes]).float().mean()\n",
    "        f1 = self.f1(pred, self.labels[output_nodes]).item()\n",
    "\n",
    "        self.log(\n",
    "            \"test_loss\", loss, prog_bar=True, on_epoch=True, batch_size=len(output_nodes)\n",
    "        )\n",
    "        self.log(\n",
    "            \"test_acc\",\n",
    "            test_acc,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            batch_size=len(output_nodes),\n",
    "        )\n",
    "        self.log(\"f1\", f1, prog_bar=True, on_epoch=True, batch_size=len(output_nodes))\n",
    "        return {\"test_loss\": loss, \"test_acc\": test_acc, \"f1\": f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m train_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m val_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([i \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m     12\u001b[0m     device\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m test_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([i \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(g\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m     15\u001b[0m     device\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=244'>245</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=245'>246</a>\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=246'>247</a>\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=247'>248</a>\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=248'>249</a>\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=249'>250</a>\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rross/.venv/ml/lib/python3.10/site-packages/torch/cuda/__init__.py?line=250'>251</a>\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "from dgl.dataloading import DataLoader\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "batch_size = len(g.ndata[\"train_mask\"])\n",
    "train_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"train_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "val_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"val_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "test_idx = torch.tensor([i for i, x in enumerate(g.ndata[\"test_mask\"]) if x > 0]).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "g = g.to(device)\n",
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\n",
    "dataloader = DataLoader(g, train_idx, sampler, batch_size=batch_size)\n",
    "val_set = DataLoader(g, val_idx, sampler, batch_size=len(val_idx))\n",
    "test_set = DataLoader(g, test_idx, sampler, batch_size=len(test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | f1    | BinaryF1Score   | 0     \n",
      "1 | conv0 | HeteroGraphConv | 3.1 K \n",
      "2 | conv1 | HeteroGraphConv | 198   \n",
      "------------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rross/.venv/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/rross/.venv/ml/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:120: UserWarning: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rross/.venv/ml/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n",
      "/home/rross/.venv/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4999: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=f933, loss_step=0.230, acc_step=0.906, val_loss=0.240, val_acc=0.900, val_f1=0.592, loss_epoch=0.230, acc_epoch=0.906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4999: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=f933, loss_step=0.230, acc_step=0.906, val_loss=0.240, val_acc=0.900, val_f1=0.592, loss_epoch=0.230, acc_epoch=0.906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/rross/.venv/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "           f1               0.6117441058158875\n",
      "        test_acc            0.9036118388175964\n",
      "        test_loss           0.23913544416427612\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.23913544416427612,\n",
       "  'test_acc': 0.9036118388175964,\n",
       "  'f1': 0.6117441058158875}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "mlf_logger = MLFlowLogger()\n",
    "model = GCN(g, g.ndata[\"feature\"].shape[1], 16, dataset.num_classes, g.etypes)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5_000,\n",
    "    # accelerator=\"cpu\",\n",
    "    log_every_n_steps=1,\n",
    "    logger=mlf_logger\n",
    ")\n",
    "trainer.fit(model, dataloader,val_dataloaders=val_set)\n",
    "trainer.test(model, dataloaders=test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rross/.venv/ml/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fabfbdbead0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "features = {\"review\": g.ndata[\"feature\"].to(device)}\n",
    "model = model.to(device)\n",
    "logits = model(g.to(device), features)[\"review\"]\n",
    "test_mask = g.ndata[\"test_mask\"].cpu().to(bool)\n",
    "labels = g.ndata[\"label\"][test_mask].cpu()\n",
    "pred = logits.argmax(1)[test_mask].cpu()\n",
    "\n",
    "cm = confusion_matrix(labels, pred)\n",
    "cm = ConfusionMatrixDisplay(cm)\n",
    "cm.plot(cmap=\"Blues\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc93820af594536f6b5955ab92df2c64c8b670a927a628d84e8130e0bffc07a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
